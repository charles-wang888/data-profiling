# data-profiling （数据库的Profiling分析总结实验）



\# 背景



假设有以下场景：  

对于一个存在问题数据的数据库（数据源），需要制作一个数据质量分析工具（profiling），来形成关于数据源的数据画像。具体诉求如下：



\## 数据分析-分析问题数据



1\. \*\*分析缺失值\*\*：分析数据中存在的缺失值并给出汇总信息。

2\. \*\*分析异常值\*\*：分析数据中存在的异常值（比如不符合正则条件的）并给出汇总信息。

3\. \*\*分析重复值\*\*：分析数据中存在的重复值并给出汇总信息。

4\. \*\*数据画像\*\*：基于以上问题数据，汇总并形成基于数据源的数据画像。



\## AI给出校验建议



基于数据源的数据画像，AI给出校验建议，例如：



\- 针对“邮箱”字段信息，推荐用正则表达式+非空校验来校验。

\- 针对“电话”字段信息，推荐用正则表达式+非空校验来校验。

\- 针对“姓名”字段信息，推荐用字符串长度来校验。



\## AI给出修复建议



基于校验建议，AI给出修复建议，例如：



\- 如果是格式错误，则AI建议用正则表达式来修正，并形成修正列表。

\- 如果是缺失值，则AI建议是否有默认值补全，并给出修正列表。

\- 如果是重复值，则AI建议保留最新的一条，其他的标出来，并形成修正列表。



---



\# 演示步骤



有4个py文件：



\- \*\*data\_prepare.py\*\*  

&nbsp; 负责生成带有问题数据的数据库，按照5%-8%的比例，在数据库中随机造一些不合理数据，比如说重复数据、正则不匹配数据、空值数据等。如果有造数工具，则这一步可以省略。



\- \*\*profile\_report.py\*\*  

&nbsp; 主要是针对若干规则进行数据质量分析，提供一组工具类。包括缺失值检测、异常值检测、重复值检测等检测维度。通过遍历表集合，对于每一张表的数据进行检测，并把检测结果形成数据源的数据画像，写入profile分析报告中。  

&nbsp; 有几个关键点：

&nbsp; 1. 对于重复检测，可以有`ignore\_table\_list`和`ignore\_column\_list`，比如对于user\_info表的region字段本身就是枚举值，所以就不在重复检测范围内。另外transaction表，因为用户数远远小于交易表的记录数，所以user\_id, transaction\_date等字段都会存在重复，因此整个这张表都不会被用于重复检测。

&nbsp; 2. 这里最精髓的地方在于基于数据分布的大多数取值来推断可能的正则，并且智能识别出怎样的取值是正确的、怎样的取值是错误的。所以有`guess\_field\_pattern`（猜字段的正则）和`guess\_field\_type`（猜测字段的类型）等技巧。



\- \*\*ai\_advice.py\*\*  

&nbsp; 负责用LLM来生成校验建议和修复建议，并把建议追加到上一步生成的报告的末尾。



\- \*\*main.py\*\*  

&nbsp; 负责把上述场景串联起来。





